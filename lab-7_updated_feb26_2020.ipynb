{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS342 Machine Learning\n",
    "## Lab 7: Convolutional neural networks\n",
    "\n",
    "### Department of Computer Science, University of Warwick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will create a convolutional neural network (CNN) to classify the images of the MNIST dataset, a widely-used dataset of hand-written digits. We will use the images that have been denoised using your denoising autoencoder from **Lab 6**. If you have not yet completed lab 6, images that have already been de-noised are available to use instead. However, you are encouraged to use your own denoised images to get top marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets for this lab are larger than those for previous labs. Therefore, we will load the data directly from the module directory, as shown below. If you would like to work on the lab using your own machine, copy the data across by running the following command in a terminal window:\n",
    "\n",
    "```scp USERNAME@login-3.dcs.warwick.ac.uk:/modules/cs342/2019/lab7/data/* .```\n",
    "\n",
    "After entering your DCS password, this will copy the data to your current working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data required for this lab. **If you have completed Lab 6, replace ```mnist_test_x_denoised.npy``` with your own denoised data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/local/java/python-pip-packages.cs342/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "train_x = np.load('/modules/cs342/2019/lab7/data/mnist_train_x.npy')\n",
    "train_y = np.load('/modules/cs342/2019/lab7/data/mnist_train_y.npy')\n",
    "test_x_noisy = np.load('/modules/cs342/2019/lab7/data/mnist_test_x.npy')\n",
    "#test_x_denoised = np.load('/modules/cs342/2019/lab7/data/mnist_test_x_denoised.npy')\n",
    "test_x_denoised = np.load('./data/mnist_test_x_denoised.npy') #my data from lab 6\n",
    "test_y = np.load('/modules/cs342/2019/lab7/data/mnist_test_y.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset consists of 60,0000 training images and 5,000 testing images. Each image is labelled with the digit it depicts, from 0 to 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape:          (60000, 28, 28)\n",
      "train_y shape:          (60000,)\n",
      "test_x_noisy shape:    (5000, 28, 28)\n",
      "test_x_denoised shape:  (5000, 784)\n",
      "test_y shape:           (5000,)\n"
     ]
    }
   ],
   "source": [
    "print('train_x shape:         ', train_x.shape)\n",
    "print('train_y shape:         ', train_y.shape)\n",
    "print('test_x_noisy shape:   ', test_x_noisy.shape)\n",
    "print('test_x_denoised shape: ', test_x_denoised.shape)\n",
    "print('test_y shape:          ', test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare the MNIST dataset for classification (5 marks)\n",
    "\n",
    "1. Normalize the training and test data to the range 0 to 1.\n",
    "\n",
    "\n",
    "2. Convert the training and test labels to one-hot encoded vectors.\n",
    "\n",
    "\n",
    "3. Use the ```np.expand_dims``` function to add an additional dimension to the training and test data in the last axis; i.e., the shape of the training set after this operation should be ```(60000, 28, 28, 1)``` . Convolutional layers in Keras expect each data point to have 3 dimensions: width, height and color channels. As the MNIST dataset consists of greyscale images, the number of channels is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "(60000, 28, 28, 1)\n",
      "(5000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.reshape(train_x,(60000,28,28))/255\n",
    "test_data = np.reshape(test_x_noisy,(5000,28,28))/255\n",
    "y_hot_train = keras.utils.to_categorical(train_y)\n",
    "y_hot_test = keras.utils.to_categorical(test_y)\n",
    "\n",
    "test_data_denoised = np.reshape(test_x_denoised,(5000,28,28)) # already normalized\n",
    "\n",
    "train_data_3ax = np.expand_dims(train_data,axis=3)\n",
    "test_data_3ax = np.expand_dims(test_data,axis=3)\n",
    "test_data_d_3ax = np.expand_dims(test_data_denoised,axis=3)\n",
    "\n",
    "print(y_hot_train[1])\n",
    "print(train_data_3ax.shape)\n",
    "print(test_data_d_3ax.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_mnist(data):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    for i in range(5):\n",
    "        axe = fig.add_subplot(1,5,i+1)\n",
    "        plt.imshow(data[i].reshape(28,28), cmap = 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_mnist(test_data_d_3ax[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Design a CNN to classify images from the MNIST dataset (50 marks)\n",
    "\n",
    "\n",
    "Use ```mnist_train_x.npy``` as the training data and ```mnist_test_x_denoised.npy``` to test your CNN. Your model should predict the label associated with each image, i.e., ```mnist_train_y.npy``` and ```mnist_test_y.npy``` for the training and test data, respectively. \n",
    "\n",
    "Use your knowledge of the different types of layers and their purpose to build a model that performs well on the testing data. You will be assessed on both the design of your model and its performance on the test data.\n",
    "\n",
    "\n",
    "You may use any combination of the following layers in Keras:\n",
    "\n",
    "- ```Conv2D()```\n",
    "- ```Dense()```\n",
    "\n",
    "You do not need to use all layer types if you do not deem it necessary to do so. You may also use the ```Flatten()```, ```MaxPooling2D()```, and ```Dropout()``` operations. These operations are added to the model in the same way as the layers above but are not considered additional layers in themselves.\n",
    "\n",
    "Once you have designed your CNN model, use the ```model.compile```, ```model.fit```, and ```model.evaluate``` functions to train and test your model.\n",
    "\n",
    "**You must design your model according to the following requirements:**\n",
    "\n",
    "1. Each training epoch must require no more than 20 seconds to complete on a DCS machine.\n",
    "\n",
    "2. The model should be trained for a maximum of 5 epochs.\n",
    "\n",
    "3. The model must use no more than 7 layers in total.\n",
    "\n",
    "This question will be marked according to the following criteria:\n",
    "\n",
    "##### Criterion 1: Design (25 marks)\n",
    "- Usage of your own denoised images from Lab 6  (5 marks)\n",
    "- Usage of some form of regularization (10 marks)\n",
    "- Sensible CNN architecture design (10 marks)\n",
    "\n",
    "\n",
    "##### Criterion 2: Performance (25 marks)\n",
    "- 70%+ Accuracy on the test set (+5 marks)\n",
    "- 80%+ Accuracy on the test set (+10 marks)\n",
    "- 85%+ Accuracy on the test set (+10 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.4258 - accuracy: 0.8661\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1453 - accuracy: 0.9559\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1110 - accuracy: 0.9654\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0975 - accuracy: 0.9699\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0855 - accuracy: 0.9734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f833dcfa6a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.05)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(50, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "model.add(Conv2D(30, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, use_bias='true', activation='sigmoid'))\n",
    "model.add(Dense(32, use_bias='true', activation='sigmoid'))\n",
    "model.add(Dense(10,use_bias='true',activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd , metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data_3ax, y_hot_train, epochs=5, batch_size=64, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 57us/step\n",
      "the accuray is 91.97999835014343 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data_d_3ax, y_hot_test, batch_size=64)\n",
    "print ('the accuray is', score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discuss your key design choices for the CNN architecture in exercise 2 (30 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider your architecture design choices in the previous exercise. Discuss your design choices for creating an effective model. In your discussion, please consider:\n",
    "\n",
    "a. Choice of activation functions.\n",
    "\n",
    "b. Choice of loss function.\n",
    "\n",
    "c. Choice of layer type and the purpose of using layers of this type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answer:\n",
    "\n",
    "Having done some research on CNNs, I decided to use a structure similar to LeNet-5. This means having the Conv2d layers at the beginning, each one followed by a MaxPooling2D layer to reduce the time needed for each epochs.\n",
    "When looking at the kernel parameter, the choice was made to have less layers to have a kernel of 3 for each Conv2D layers.\n",
    "\n",
    "The Dropout layer should reduce the overfitting effect and increase the running speed slightly.\n",
    "2 hidden Dense layers help increasing the accuracy and the output layer has 10 neurons as the one hot encoded vectors have 10 elements in their arrays. The output has a softmax activation function rather than a sigmoid as it was found through testing than the CNN would gain in accuracy.\n",
    "\n",
    "It is important to notice that the activation functions for the Conv2D layers and the Dense ones are different. After some testing, Conv2D seemed to work better with a relu activation function, when the Dense layers work better with a sigmoid function.\n",
    "\n",
    "The Loss function is categorical_crossentropy as there are 10 different classes. I used binary_crossentropy by inattention for sometimes and the CNN would look like it was working well. However, it was only assigning the right values to one class and not split the data between the ten categories.\n",
    "\n",
    "A mistake I made at the beginning was to have a learning rate quite high. This would lead to a poor accuracy. When reduced to 0.05, the CNN worked a lot more effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test your CNN using MNIST images before denoising (15 marks)\n",
    "Test your CNN using the noisy images (```mnist_test_x.npy```) after training on the clean images (```mnist_train_x.npy```). How does the model perform compared to testing with the denoised images? Please explain your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 54us/step\n",
      "the accuray is 81.19999766349792 %\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data_3ax, y_hot_test, batch_size=64)\n",
    "print ('the accuray is', score[1]*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deliverables\n",
    "\n",
    "Submit via Tabula:\n",
    "\n",
    "1. The code and discussions for Lab 6 and Lab 7 as separate Jupyter files.\n",
    "\n",
    "2. Your own denoised data ```mnist_test_x_denoised.npy``` if these data were used in this Lab.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
